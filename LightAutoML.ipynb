{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "Выполнил: Кузьмин Андрей, tg: @thisismoto"
      ],
      "metadata": {
        "id": "Xdcj7ogb0KtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/overview"
      ],
      "metadata": {
        "id": "ZJGRIK1FIMRP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvbIwJgz_1X7"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noCoU28p_1X7",
        "outputId": "6c927ef7-23ea-4ae3-ab19-94893ce3ef20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightautoml[nlp]\n",
            "  Downloading lightautoml-0.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: SQLAlchemy>=2.0 in /usr/local/lib/python3.11/dist-packages (from lightautoml[nlp]) (2.0.37)\n",
            "Collecting autowoe>=1.3.3 (from lightautoml[nlp])\n",
            "  Downloading autowoe-1.3.3-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting catboost>=0.26.1 (from lightautoml[nlp])\n",
            "  Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting cmaes (from lightautoml[nlp])\n",
            "  Downloading cmaes-0.11.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: gensim>=4 in /usr/local/lib/python3.11/dist-packages (from lightautoml[nlp]) (4.3.3)\n",
            "Requirement already satisfied: holidays in /usr/local/lib/python3.11/dist-packages (from lightautoml[nlp]) (0.64)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from lightautoml[nlp]) (3.1.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from lightautoml[nlp]) (1.4.2)\n",
            "Collecting json2html (from lightautoml[nlp])\n",
            "  Downloading json2html-1.3.0.tar.gz (7.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lightgbm>=2.3 in /usr/local/lib/python3.11/dist-packages (from lightautoml[nlp]) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from lightautoml[nlp]) (3.4.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from lightautoml[nlp]) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/dist-packages (from lightautoml[nlp]) (1.26.4)\n",
            "Collecting optuna (from lightautoml[nlp])\n",
            "  Downloading optuna-4.2.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from lightautoml[nlp]) (2.2.2)\n",
            "Collecting poetry-core<2.0.0,>=1.0.0 (from lightautoml[nlp])\n",
            "  Downloading poetry_core-1.9.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from lightautoml[nlp]) (6.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.11/dist-packages (from lightautoml[nlp]) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightautoml[nlp]) (1.13.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from lightautoml[nlp]) (0.13.2)\n",
            "Collecting statsmodels<=0.14.0 (from lightautoml[nlp])\n",
            "  Downloading statsmodels-0.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from lightautoml[nlp]) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from lightautoml[nlp]) (4.67.1)\n",
            "Requirement already satisfied: transformers>=4 in /usr/local/lib/python3.11/dist-packages (from lightautoml[nlp]) (4.47.1)\n",
            "Requirement already satisfied: xgboost<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from lightautoml[nlp]) (2.1.3)\n",
            "Collecting StrEnum<0.5.0,>=0.4.7 (from autowoe>=1.3.3->lightautoml[nlp])\n",
            "  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from autowoe>=1.3.3->lightautoml[nlp]) (3.10.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from autowoe>=1.3.3->lightautoml[nlp]) (8.3.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from autowoe>=1.3.3->lightautoml[nlp]) (2024.2)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.11/dist-packages (from autowoe>=1.3.3->lightautoml[nlp]) (8.1.3)\n",
            "Collecting sphinx-rtd-theme (from autowoe>=1.3.3->lightautoml[nlp])\n",
            "  Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost>=0.26.1->lightautoml[nlp]) (0.20.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost>=0.26.1->lightautoml[nlp]) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost>=0.26.1->lightautoml[nlp]) (1.17.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim>=4->lightautoml[nlp]) (7.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->lightautoml[nlp]) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->lightautoml[nlp]) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22->lightautoml[nlp]) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=2.0->lightautoml[nlp]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=2.0->lightautoml[nlp]) (4.12.2)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from statsmodels<=0.14.0->lightautoml[nlp]) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels<=0.14.0->lightautoml[nlp]) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->lightautoml[nlp]) (3.16.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->lightautoml[nlp]) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->lightautoml[nlp]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->lightautoml[nlp]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->lightautoml[nlp]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->lightautoml[nlp]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->lightautoml[nlp]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->lightautoml[nlp]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->lightautoml[nlp]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->lightautoml[nlp]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->lightautoml[nlp]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->lightautoml[nlp]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->lightautoml[nlp]) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->lightautoml[nlp]) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->lightautoml[nlp]) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9.0->lightautoml[nlp]) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9.0->lightautoml[nlp]) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4->lightautoml[nlp]) (0.27.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4->lightautoml[nlp]) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4->lightautoml[nlp]) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4->lightautoml[nlp]) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4->lightautoml[nlp]) (0.5.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->lightautoml[nlp]) (3.0.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->lightautoml[nlp]) (8.1.8)\n",
            "Collecting alembic>=1.5.0 (from optuna->lightautoml[nlp])\n",
            "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna->lightautoml[nlp])\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna->lightautoml[nlp])\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml[nlp]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml[nlp]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml[nlp]) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml[nlp]) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml[nlp]) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml[nlp]) (3.2.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim>=4->lightautoml[nlp]) (1.17.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost>=0.26.1->lightautoml[nlp]) (9.0.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->autowoe>=1.3.3->lightautoml[nlp]) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->autowoe>=1.3.3->lightautoml[nlp]) (1.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4->lightautoml[nlp]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4->lightautoml[nlp]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4->lightautoml[nlp]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4->lightautoml[nlp]) (2024.12.14)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml[nlp]) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml[nlp]) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml[nlp]) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml[nlp]) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml[nlp]) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.11/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml[nlp]) (2.0.0)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.11/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml[nlp]) (2.18.0)\n",
            "Requirement already satisfied: docutils<0.22,>=0.20 in /usr/local/lib/python3.11/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml[nlp]) (0.21.2)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.11/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml[nlp]) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.11/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml[nlp]) (2.16.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.11/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml[nlp]) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.11/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml[nlp]) (1.4.1)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->autowoe>=1.3.3->lightautoml[nlp])\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Downloading autowoe-1.3.3-py3-none-any.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.0/216.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading poetry_core-1.9.1-py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.5/309.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading statsmodels-0.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmaes-0.11.1-py3-none-any.whl (35 kB)\n",
            "Downloading lightautoml-0.4.0-py3-none-any.whl (399 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.6/399.6 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.2.0-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.4/383.4 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: json2html\n",
            "  Building wheel for json2html (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for json2html: filename=json2html-1.3.0-py3-none-any.whl size=7594 sha256=f97655e541835220175e3e0e1abe6d3cb7c249b6698fdf98a79f533bc14abfc6\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/8b/96/b33d26a9d72d6c8ac50ef1fe81089c350a9fdcf51feab22144\n",
            "Successfully built json2html\n",
            "Installing collected packages: StrEnum, json2html, poetry-core, Mako, colorlog, cmaes, alembic, statsmodels, sphinxcontrib-jquery, optuna, catboost, sphinx-rtd-theme, autowoe, lightautoml\n",
            "  Attempting uninstall: statsmodels\n",
            "    Found existing installation: statsmodels 0.14.4\n",
            "    Uninstalling statsmodels-0.14.4:\n",
            "      Successfully uninstalled statsmodels-0.14.4\n",
            "Successfully installed Mako-1.3.8 StrEnum-0.4.15 alembic-1.14.1 autowoe-1.3.3 catboost-1.2.7 cmaes-0.11.1 colorlog-6.9.0 json2html-1.3.0 lightautoml-0.4.0 optuna-4.2.0 poetry-core-1.9.1 sphinx-rtd-theme-3.0.2 sphinxcontrib-jquery-4.1 statsmodels-0.14.0\n"
          ]
        }
      ],
      "source": [
        "!pip install lightautoml[nlp]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYIrFIYv_1X9",
        "outputId": "48508ce7-ee0b-4a67-f9a0-138a536b6942"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from lightautoml.automl.presets.text_presets import TabularNLPAutoML\n",
        "from lightautoml.tasks import Task\n",
        "\n",
        "from lightautoml.addons.interpretation import LimeTextExplainer, L2XTextExplainer\n",
        "\n",
        "import transformers\n",
        "transformers.logging.set_verbosity(50)\n",
        "\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQ6tkyWr_1X9"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip jigsaw-toxic-comment-classification-challenge.zip\n",
        "!unzip train.csv.zip\n",
        "!unzip test.csv.zip\n",
        "!unzip sample_submission.csv.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mcxFqrAEkj0",
        "outputId": "740fef1c-d6e0-4055-8fa7-0a33460b0eb5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  jigsaw-toxic-comment-classification-challenge.zip\n",
            "  inflating: sample_submission.csv.zip  \n",
            "  inflating: test.csv.zip            \n",
            "  inflating: test_labels.csv.zip     \n",
            "  inflating: train.csv.zip           \n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n",
            "Archive:  sample_submission.csv.zip\n",
            "  inflating: sample_submission.csv   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "subm = pd.read_csv('sample_submission.csv')"
      ],
      "metadata": {
        "id": "9TBDhTfAVLXs"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subm = test.merge(subm, on='id')"
      ],
      "metadata": {
        "id": "LpnZxEe4IVjh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "id": "lyRK1hZ1hrLj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "13d3e475-c8b1-409b-f563-68c2fe69122d"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      id                                       comment_text  \\\n",
              "140030  ed56f082116dcbd0  Grandma Terri Should Burn in Trash \\nGrandma T...   \n",
              "159124  f8e3cd98b63bf401  , 9 May 2009 (UTC)\\nIt would be easiest if you...   \n",
              "60006   a09e1bcf10631f9a  \"\\n\\nThe Objectivity of this Discussion is dou...   \n",
              "65432   af0ee0066c607eb8              Shelly Shock\\nShelly Shock is. . .( )   \n",
              "154979  b734772b1a807e09  I do not care. Refer to Ong Teng Cheong talk p...   \n",
              "\n",
              "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
              "140030      1             0        0       0       0              0  \n",
              "159124      0             0        0       0       0              0  \n",
              "60006       0             0        0       0       0              0  \n",
              "65432       0             0        0       0       0              0  \n",
              "154979      0             0        0       0       0              0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc22d0c7-7c6c-4c59-b83c-72854e1d8aca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>140030</th>\n",
              "      <td>ed56f082116dcbd0</td>\n",
              "      <td>Grandma Terri Should Burn in Trash \\nGrandma T...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159124</th>\n",
              "      <td>f8e3cd98b63bf401</td>\n",
              "      <td>, 9 May 2009 (UTC)\\nIt would be easiest if you...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60006</th>\n",
              "      <td>a09e1bcf10631f9a</td>\n",
              "      <td>\"\\n\\nThe Objectivity of this Discussion is dou...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65432</th>\n",
              "      <td>af0ee0066c607eb8</td>\n",
              "      <td>Shelly Shock\\nShelly Shock is. . .( )</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154979</th>\n",
              "      <td>b734772b1a807e09</td>\n",
              "      <td>I do not care. Refer to Ong Teng Cheong talk p...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc22d0c7-7c6c-4c59-b83c-72854e1d8aca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cc22d0c7-7c6c-4c59-b83c-72854e1d8aca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cc22d0c7-7c6c-4c59-b83c-72854e1d8aca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1d947452-10db-4d8c-a293-9328e1263277\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1d947452-10db-4d8c-a293-9328e1263277')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1d947452-10db-4d8c-a293-9328e1263277 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5kkbhOkR8Wf5",
        "outputId": "53d74d39-7ca5-4d2c-d69b-893682299ffe"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      id                                       comment_text  \\\n",
              "119105  7ca72b5b9c688e9e  Geez, are you forgetful!  We've already discus...   \n",
              "131631  c03f72fd8f8bf54f  Carioca RFA \\n\\nThanks for your support on my ...   \n",
              "125326  9e5b8e8fc1ff2e84  \"\\n\\n Birthday \\n\\nNo worries, It's what I do ...   \n",
              "111256  5332799e706665a6  Pseudoscience category? \\n\\nI'm assuming that ...   \n",
              "83590   dfa7d8f0b4366680  (and if such phrase exists, it would be provid...   \n",
              "\n",
              "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
              "119105      0             0        0       0       0              0  \n",
              "131631      0             0        0       0       0              0  \n",
              "125326      0             0        0       0       0              0  \n",
              "111256      0             0        0       0       0              0  \n",
              "83590       0             0        0       0       0              0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bbbac62c-0e38-4786-acf3-25f6fb088c42\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>119105</th>\n",
              "      <td>7ca72b5b9c688e9e</td>\n",
              "      <td>Geez, are you forgetful!  We've already discus...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131631</th>\n",
              "      <td>c03f72fd8f8bf54f</td>\n",
              "      <td>Carioca RFA \\n\\nThanks for your support on my ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125326</th>\n",
              "      <td>9e5b8e8fc1ff2e84</td>\n",
              "      <td>\"\\n\\n Birthday \\n\\nNo worries, It's what I do ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111256</th>\n",
              "      <td>5332799e706665a6</td>\n",
              "      <td>Pseudoscience category? \\n\\nI'm assuming that ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83590</th>\n",
              "      <td>dfa7d8f0b4366680</td>\n",
              "      <td>(and if such phrase exists, it would be provid...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbbac62c-0e38-4786-acf3-25f6fb088c42')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bbbac62c-0e38-4786-acf3-25f6fb088c42 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bbbac62c-0e38-4786-acf3-25f6fb088c42');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cf06fb7a-56ea-47a4-aa57-5c6798b77bb9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cf06fb7a-56ea-47a4-aa57-5c6798b77bb9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cf06fb7a-56ea-47a4-aa57-5c6798b77bb9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test",
              "summary": "{\n  \"name\": \"test\",\n  \"rows\": 31915,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31915,\n        \"samples\": [\n          \"6c87cef0213e9af7\",\n          \"3b1bbb47929c3354\",\n          \"08ad981dc1154f38\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comment_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31915,\n        \"samples\": [\n          \"\\\"\\nOf course. I feel like the Maxie page could be extremely well put once it's organized and edited a lot. And I want to do it, I just need time.  TALK! \\\"\",\n          \"\\\"\\n\\nI'll give you time. BTW, \\\"\\\"vandalism\\\"\\\" is an incorrect word here. Take the time to read Wikipedia:Vandalism. For example, this is vandalism, what Irpen was doing was not. Ciao. \\u2014 \\\"\",\n          \"you can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou can't keep me down nigger \\nyou c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"toxic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"severe_toxic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"obscene\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"threat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"insult\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"identity_hate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subm.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cuCINqgt8ZiA",
        "outputId": "4941fecc-5079-44e8-bd1f-01dbcfe608c0"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id                                       comment_text  toxic  \\\n",
              "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...    0.5   \n",
              "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...    0.5   \n",
              "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...    0.5   \n",
              "3  00017563c3f7919a  :If you have a look back at the source, the in...    0.5   \n",
              "4  00017695ad8997eb          I don't anonymously edit articles at all.    0.5   \n",
              "\n",
              "   severe_toxic  obscene  threat  insult  identity_hate  \n",
              "0           0.5      0.5     0.5     0.5            0.5  \n",
              "1           0.5      0.5     0.5     0.5            0.5  \n",
              "2           0.5      0.5     0.5     0.5            0.5  \n",
              "3           0.5      0.5     0.5     0.5            0.5  \n",
              "4           0.5      0.5     0.5     0.5            0.5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cfdc529a-627e-42d5-8815-ad46f8db8e8a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>:If you have a look back at the source, the in...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>I don't anonymously edit articles at all.</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfdc529a-627e-42d5-8815-ad46f8db8e8a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cfdc529a-627e-42d5-8815-ad46f8db8e8a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cfdc529a-627e-42d5-8815-ad46f8db8e8a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3a928025-2348-4d25-991c-9b4468347ee8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3a928025-2348-4d25-991c-9b4468347ee8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3a928025-2348-4d25-991c-9b4468347ee8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "subm"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['comment_text'][140030]"
      ],
      "metadata": {
        "id": "HGs7blhShtci",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4cc2344a-5d7f-438b-b250-08b808172d22"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Grandma Terri Should Burn in Trash \\nGrandma Terri is trash. I hate Grandma Terri. F%%K her to HELL! 71.74.76.40'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['comment_text'].tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "zuHygmol81_H",
        "outputId": "5dab1c36-fd11-42c7-8e08-e3ac7bfe6335"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119879    REDIRECT Talk:John Loveday (experimental physi...\n",
              "103694    Back it up. Post the line here with the refere...\n",
              "131932    I won't stop that. Sometimes Germanic equals G...\n",
              "146867    \"\\n\\n British Bands?  \\n\\nI think you've mista...\n",
              "121958    You are WRONG. \\n\\nJustin Thompson is mentione...\n",
              "Name: comment_text, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>119879</th>\n",
              "      <td>REDIRECT Talk:John Loveday (experimental physi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103694</th>\n",
              "      <td>Back it up. Post the line here with the refere...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131932</th>\n",
              "      <td>I won't stop that. Sometimes Germanic equals G...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146867</th>\n",
              "      <td>\"\\n\\n British Bands?  \\n\\nI think you've mista...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121958</th>\n",
              "      <td>You are WRONG. \\n\\nJustin Thompson is mentione...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['comment_text'][103694]"
      ],
      "metadata": {
        "id": "KVVFUkkHhvbz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "80a3375c-bb50-48a9-f50f-945275cc9ec6"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Back it up. Post the line here with the reference.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lens = train.comment_text.str.len()\n",
        "lens.mean(), lens.std(), lens.max()"
      ],
      "metadata": {
        "id": "0T3HCWtghx0G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a30701a6-bab3-4823-e1b5-9ccbdfa8b270"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(395.248276618412, 593.4303724527018, 5000)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lens.hist();"
      ],
      "metadata": {
        "id": "q6vLiy9bhxoY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "1c6a32c3-e178-40b4-9dab-84364a7410b3"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "train['none'] = 1-train[label_cols].max(axis=1)\n",
        "train.describe()"
      ],
      "metadata": {
        "id": "V-e9vAXphY_U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "f9458042-f09d-4ee4-db29-6835ce4ac33e"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               toxic  severe_toxic        obscene         threat  \\\n",
              "count  127656.000000  127656.00000  127656.000000  127656.000000   \n",
              "mean        0.095867       0.00998       0.052751       0.003165   \n",
              "std         0.294410       0.09940       0.223537       0.056167   \n",
              "min         0.000000       0.00000       0.000000       0.000000   \n",
              "25%         0.000000       0.00000       0.000000       0.000000   \n",
              "50%         0.000000       0.00000       0.000000       0.000000   \n",
              "75%         0.000000       0.00000       0.000000       0.000000   \n",
              "max         1.000000       1.00000       1.000000       1.000000   \n",
              "\n",
              "              insult  identity_hate           none  \n",
              "count  127656.000000  127656.000000  127656.000000  \n",
              "mean        0.049062       0.008703       0.898313  \n",
              "std         0.215997       0.092884       0.302238  \n",
              "min         0.000000       0.000000       0.000000  \n",
              "25%         0.000000       0.000000       1.000000  \n",
              "50%         0.000000       0.000000       1.000000  \n",
              "75%         0.000000       0.000000       1.000000  \n",
              "max         1.000000       1.000000       1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6af47967-7ccb-443a-8903-7b018e1c9feb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>none</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>127656.000000</td>\n",
              "      <td>127656.00000</td>\n",
              "      <td>127656.000000</td>\n",
              "      <td>127656.000000</td>\n",
              "      <td>127656.000000</td>\n",
              "      <td>127656.000000</td>\n",
              "      <td>127656.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.095867</td>\n",
              "      <td>0.00998</td>\n",
              "      <td>0.052751</td>\n",
              "      <td>0.003165</td>\n",
              "      <td>0.049062</td>\n",
              "      <td>0.008703</td>\n",
              "      <td>0.898313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.294410</td>\n",
              "      <td>0.09940</td>\n",
              "      <td>0.223537</td>\n",
              "      <td>0.056167</td>\n",
              "      <td>0.215997</td>\n",
              "      <td>0.092884</td>\n",
              "      <td>0.302238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6af47967-7ccb-443a-8903-7b018e1c9feb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6af47967-7ccb-443a-8903-7b018e1c9feb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6af47967-7ccb-443a-8903-7b018e1c9feb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e0488e8b-86cf-45f9-910d-9f44acf0f74d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0488e8b-86cf-45f9-910d-9f44acf0f74d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e0488e8b-86cf-45f9-910d-9f44acf0f74d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"toxic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45133.14141128208,\n        \"min\": 0.0,\n        \"max\": 127656.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.09586701760982641,\n          1.0,\n          0.29440993790086983\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"severe_toxic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45133.15559873003,\n        \"min\": 0.0,\n        \"max\": 127656.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.009979946105157612,\n          1.0,\n          0.0994003228351258\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"obscene\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45133.14716858003,\n        \"min\": 0.0,\n        \"max\": 127656.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.05275114369869023,\n          1.0,\n          0.2235371377890998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"threat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45133.15812656088,\n        \"min\": 0.0,\n        \"max\": 127656.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0031647552798145014,\n          1.0,\n          0.05616728867265426\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"insult\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45133.14773574868,\n        \"min\": 0.0,\n        \"max\": 127656.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.049061540389797584,\n          1.0,\n          0.21599738683079317\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"identity_hate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45133.15599235744,\n        \"min\": 0.0,\n        \"max\": 127656.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.008703077019489878,\n          1.0,\n          0.09288380404068462\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"none\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45132.94896374387,\n        \"min\": 0.0,\n        \"max\": 127656.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8983126527542771,\n          1.0,\n          0.3022378967522626\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train), len(test)"
      ],
      "metadata": {
        "id": "BuU_W36whcqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39a7d756-57f4-4808-e642-a666ee45f35b"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(127656, 153164)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automl binary"
      ],
      "metadata": {
        "id": "0HMZLWONPeoW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-XikLsV_1X-"
      },
      "source": [
        "### Toxic model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8tUebhyZ_1X-"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "roles = {\n",
        "    'text': ['comment_text'],\n",
        "    'drop': ['id', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'],\n",
        "    'target': 'toxic'\n",
        "}\n",
        "\n",
        "task = Task('binary')\n",
        "\n",
        "automl_toxic = TabularNLPAutoML(\n",
        "    task=task,\n",
        "    timeout=900,\n",
        "    cpu_limit=2,\n",
        "    gpu_ids='0',\n",
        "    general_params={\n",
        "        'nested_cv': False,\n",
        "        'use_algos': [['nn']]\n",
        "    },\n",
        "    autonlp_params={\n",
        "        'sent_scaler': 'l2'\n",
        "    },\n",
        "    text_params={\n",
        "        'lang': 'en',\n",
        "        'bert_model': 'prajjwal1/bert-tiny'\n",
        "    },\n",
        "    nn_params={\n",
        "        'opt_params': {'lr': 1e-5},\n",
        "        'max_length': 128,\n",
        "        'bs': 32,\n",
        "        'n_epochs': 2,\n",
        "    }\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "dc8353c177f64d82857ea915eca27d90",
            "bcdfba5a26e84f2a9ffc7193f3d9b1f4",
            "985b563f947d4389b363b8edd398e26b",
            "7db35c0980234888beb9e31dc4d508fc",
            "44e01017275c4e23b036424c61c336fc",
            "962270b3f0aa47b88265a4982aa1d0e6",
            "a1a52213370143a2867c7f55369f6f59",
            "5d8adce041264808ab961843960dc9f7",
            "239a76d1404346a4b0a4b2e12dbc92f1",
            "ad97b62eda2747688076b117c06052cb",
            "86f943fd4b694711ab174ec334c653a6",
            "a2058a13d2674acd91c5c3499fb3406a",
            "b2b64de67665462b898ea7903ce2e398",
            "b1c3d0f2aa984644acd61e0338189725",
            "eb8102905e184222a955d73fad4b562c",
            "1c8a5b8eea764379a7fe3327f3d5fcde",
            "c403bab3dfb640dfa9cf8c0b74ead778",
            "356e563fc328456db2bb446133700452",
            "ccaff2c16e4440828d4adc46e2c3e6cb",
            "39612e8fdaa3412683a9806930bfe6e5",
            "7d83201051be40148c32d78ff0171b7f",
            "f2c7c51bc988445c9a04c762a3406e47",
            "d8b44c3690d94072af82ab15abbd415a",
            "7cf7274cdf554c8dbe48452081123b7d",
            "1f4d827dd8ec4603bfb1c12f8aedb2c9",
            "9339203b69184dc5a8baa24ba523e832",
            "541311f41a544d7ea722061bbf54e89b",
            "2e32f7c43f3c4cffa82bdc3ea0446d19",
            "636cbfe7b4ff4ffbba35c066165cbc28",
            "c005642ec2ff46df8a0946adf97f027b",
            "a188b603aa2248d898c68f9a75cab30e",
            "ad31ccffe7de49d1a4b97377c8bf74c3",
            "75baef9ef3de4827b7b0d21a13a76ed5"
          ]
        },
        "id": "rZoAKm3D_1X_",
        "outputId": "d1acc5e6-8df3-45d3-abae-fdb9778b5dd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:28:54] Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:28:54] Model language mode: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.automl.presets.text_presets:Model language mode: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:28:54] Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:28:54] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:28:54] - time: 900.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 900.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:28:54] - CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:28:54] - memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:28:54] \u001b[1mTrain data shape: (127656, 8)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (127656, 8)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:28:54] Layer \u001b[1m1\u001b[0m train process start. Time left 899.88 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 899.88 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:28:55] number of text features: 1 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of text features: 1 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:28:55] number of categorical features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of categorical features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:28:55] number of continuous features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of continuous features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:28:55] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:28:55] Training params: {'num_workers': 2, 'pin_memory': False, 'max_length': 128, 'is_snap': False, 'input_bn': False, 'max_emb_size': 50, 'bert_name': 'prajjwal1/bert-tiny', 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': False, 'multigpu': False, 'random_state': 42, 'model': '_linear_layer', 'model_with_emb': False, 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 1, 'early_stopping': True, 'patience': 1, 'swa': False}, 'bs': 32, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'lr': 1e-05}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 5, 'factor': 0.5, 'verbose': True}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'optimization_search_space': None, 'verbose_bar': False, 'freeze_defaults': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'embedding_size': 10, 'cat_embedder': 'cat', 'cont_embedder': 'cont', 'stop_by_metric': False, 'device_ids': None, 'num_dims': 0, 'text_features': ['concated__comment_text'], 'bias': array([-2.24401446])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.base:Training params: {'num_workers': 2, 'pin_memory': False, 'max_length': 128, 'is_snap': False, 'input_bn': False, 'max_emb_size': 50, 'bert_name': 'prajjwal1/bert-tiny', 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': False, 'multigpu': False, 'random_state': 42, 'model': '_linear_layer', 'model_with_emb': False, 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 1, 'early_stopping': True, 'patience': 1, 'swa': False}, 'bs': 32, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'lr': 1e-05}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 5, 'factor': 0.5, 'verbose': True}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'optimization_search_space': None, 'verbose_bar': False, 'freeze_defaults': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'embedding_size': 10, 'cat_embedder': 'cat', 'cont_embedder': 'cont', 'stop_by_metric': False, 'device_ids': None, 'num_dims': 0, 'text_features': ['concated__comment_text'], 'bias': array([-2.24401446])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:28:55] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/285 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc8353c177f64d82857ea915eca27d90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2058a13d2674acd91c5c3499fb3406a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/17.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8b44c3690d94072af82ab15abbd415a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:29:03] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:33:05] Epoch: 0, train loss: 0.6413275003433228, val loss: 0.5243892073631287, val metric: 0.9524577079740194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: 0.6413275003433228, val loss: 0.5243892073631287, val metric: 0.9524577079740194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:36:50] Epoch: 1, train loss: 0.5678825378417969, val loss: 0.5338758230209351, val metric: 0.9635760658885097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 1, train loss: 0.5678825378417969, val loss: 0.5338758230209351, val metric: 0.9635760658885097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:36:51] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:36:52] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:40:59] Epoch: 0, train loss: 0.6419970393180847, val loss: 0.5442343354225159, val metric: 0.9544568486426299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: 0.6419970393180847, val loss: 0.5442343354225159, val metric: 0.9544568486426299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:45:02] Epoch: 1, train loss: 0.5654829144477844, val loss: 0.5336108207702637, val metric: 0.9632351765596996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 1, train loss: 0.5654829144477844, val loss: 0.5336108207702637, val metric: 0.9632351765596996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:45:03] Time limit exceeded after calculating fold 1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:45:03] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m finished. score = \u001b[1m0.9633373755546711\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m finished. score = \u001b[1m0.9633373755546711\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:45:03] \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:45:03] Time left -69.45 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left -69.45 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:45:03] Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:45:03] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:45:03] \u001b[1mAutoml preset training completed in 969.46 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 969.46 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:45:03] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:45:04] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:46:04] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'sumb' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sumb' is not defined"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "oof_pred_toxic = automl_toxic.fit_predict(train, roles=roles, verbose = 10)\n",
        "test_pred_toxic = automl_toxic.predict(test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "not_nan = np.any(~np.isnan(oof_pred_toxic.data), axis=1)\n",
        "\n",
        "sumb_toxic = automl_toxic.predict(subm)\n",
        "\n",
        "print('Check scores:')\n",
        "print('OOF score: {}'.format(roc_auc_score(train[roles['target']].values[not_nan], oof_pred_toxic.data[not_nan][:, 0])))\n",
        "print('TEST score: {}'.format(roc_auc_score(test[roles['target']].values, test_pred_toxic.data[:, 0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttK5DVHEN3Wq",
        "outputId": "35b25bbd-dc8e-470f-bcc6-2ef24c7f2871"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n",
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check scores:\n",
            "OOF score: 0.9633373755546711\n",
            "TEST score: 0.9604387209231234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(sumb_toxic.data).to_csv('sumb_toxic.csv', index=False)"
      ],
      "metadata": {
        "id": "iu783gigORRg"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5U7NWfvJCcT"
      },
      "source": [
        "### Severe_toxic model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "lT6vUfMqJCcZ"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "roles = {\n",
        "    'text': ['comment_text'],\n",
        "    'drop': ['id', 'toxic', 'obscene', 'threat', 'insult', 'identity_hate'],\n",
        "    'target': 'severe_toxic'\n",
        "}\n",
        "\n",
        "task = Task('binary')\n",
        "\n",
        "automl_severe_toxic = TabularNLPAutoML(\n",
        "    task=task,\n",
        "    timeout=900,\n",
        "    cpu_limit=2,\n",
        "    gpu_ids='0',\n",
        "    general_params={\n",
        "        'nested_cv': False,\n",
        "        'use_algos': [['nn']]\n",
        "    },\n",
        "    autonlp_params={\n",
        "        'sent_scaler': 'l2'\n",
        "    },\n",
        "    text_params={\n",
        "        'lang': 'en',\n",
        "        'bert_model': 'prajjwal1/bert-tiny'\n",
        "    },\n",
        "    nn_params={\n",
        "        'opt_params': {'lr': 1e-5},\n",
        "        'max_length': 128,\n",
        "        'bs': 32,\n",
        "        'n_epochs': 2,\n",
        "    }\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf6069e-eb61-4a0a-c2a1-eb13fc727a69",
        "id": "fQUgH4LeJCca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:05:23] Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:05:23] Model language mode: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.automl.presets.text_presets:Model language mode: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:05:23] Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:05:23] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:05:23] - time: 900.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 900.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:05:23] - CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:05:23] - memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:05:23] \u001b[1mTrain data shape: (127656, 8)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (127656, 8)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:05:23] Layer \u001b[1m1\u001b[0m train process start. Time left 899.92 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 899.92 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:05:23] number of text features: 1 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of text features: 1 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:05:23] number of categorical features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of categorical features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:05:23] number of continuous features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of continuous features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:05:23] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:05:23] Training params: {'num_workers': 2, 'pin_memory': False, 'max_length': 128, 'is_snap': False, 'input_bn': False, 'max_emb_size': 50, 'bert_name': 'prajjwal1/bert-tiny', 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': False, 'multigpu': False, 'random_state': 42, 'model': '_linear_layer', 'model_with_emb': False, 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 1, 'early_stopping': True, 'patience': 1, 'swa': False}, 'bs': 32, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'lr': 1e-05}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 5, 'factor': 0.5, 'verbose': True}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'optimization_search_space': None, 'verbose_bar': False, 'freeze_defaults': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'embedding_size': 10, 'cat_embedder': 'cat', 'cont_embedder': 'cont', 'stop_by_metric': False, 'device_ids': None, 'num_dims': 0, 'text_features': ['concated__comment_text'], 'bias': array([-4.59714751])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.base:Training params: {'num_workers': 2, 'pin_memory': False, 'max_length': 128, 'is_snap': False, 'input_bn': False, 'max_emb_size': 50, 'bert_name': 'prajjwal1/bert-tiny', 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': False, 'multigpu': False, 'random_state': 42, 'model': '_linear_layer', 'model_with_emb': False, 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 1, 'early_stopping': True, 'patience': 1, 'swa': False}, 'bs': 32, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'lr': 1e-05}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 5, 'factor': 0.5, 'verbose': True}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'optimization_search_space': None, 'verbose_bar': False, 'freeze_defaults': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'embedding_size': 10, 'cat_embedder': 'cat', 'cont_embedder': 'cont', 'stop_by_metric': False, 'device_ids': None, 'num_dims': 0, 'text_features': ['concated__comment_text'], 'bias': array([-4.59714751])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:05:23] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:05:24] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:09:15] Epoch: 0, train loss: 0.7624977231025696, val loss: 0.7148200869560242, val metric: 0.9617417369973988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: 0.7624977231025696, val loss: 0.7148200869560242, val metric: 0.9617417369973988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:13:01] Epoch: 1, train loss: 0.7241961359977722, val loss: 0.6814936995506287, val metric: 0.97614849891436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 1, train loss: 0.7241961359977722, val loss: 0.6814936995506287, val metric: 0.97614849891436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:13:01] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:13:02] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:16:44] Epoch: 0, train loss: 0.7618426084518433, val loss: 0.6921765804290771, val metric: 0.9681058535883791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: 0.7618426084518433, val loss: 0.6921765804290771, val metric: 0.9681058535883791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:20:33] Epoch: 1, train loss: 0.7246556282043457, val loss: 0.7113555073738098, val metric: 0.9784414075645212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 1, train loss: 0.7246556282043457, val loss: 0.7113555073738098, val metric: 0.9784414075645212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:20:33] Time limit exceeded after calculating fold 1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:20:33] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m finished. score = \u001b[1m0.9771130309378975\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m finished. score = \u001b[1m0.9771130309378975\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:20:33] \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:20:33] Time left -10.33 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left -10.33 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:20:33] Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:20:33] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:20:33] \u001b[1mAutoml preset training completed in 910.34 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 910.34 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:20:33] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:20:34] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:21:34] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:22:27] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:26:30] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check scores:\n",
            "OOF score: 0.9771130309378975\n",
            "TEST score: 0.9767000990171839\n",
            "CPU times: user 4min 30s, sys: 17.8 s, total: 4min 48s\n",
            "Wall time: 25min\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "oof_pred_severe_toxic = automl_severe_toxic.fit_predict(train, roles=roles, verbose = 10)\n",
        "test_pred_severe_toxic = automl_severe_toxic.predict(test)\n",
        "not_nan = np.any(~np.isnan(oof_pred_severe_toxic.data), axis=1)\n",
        "\n",
        "sumb_severe_toxic = automl_severe_toxic.predict(subm)\n",
        "\n",
        "print('Check scores:')\n",
        "print('OOF score: {}'.format(roc_auc_score(train[roles['target']].values[not_nan], oof_pred_severe_toxic.data[not_nan][:, 0])))\n",
        "print('TEST score: {}'.format(roc_auc_score(test[roles['target']].values, test_pred_severe_toxic.data[:, 0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "bErP-63CJCcb"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(sumb_severe_toxic.data).to_csv('sumb_severe_toxic.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIx-AAafKm3j"
      },
      "source": [
        "### Obscene model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "voo2gsOgKm3m"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "roles = {\n",
        "    'text': ['comment_text'],\n",
        "    'drop': ['id', 'toxic', 'severe_toxic', 'threat', 'insult', 'identity_hate'],\n",
        "    'target': 'obscene'\n",
        "}\n",
        "\n",
        "task = Task('binary')\n",
        "\n",
        "automl_obscene = TabularNLPAutoML(\n",
        "    task=task,\n",
        "    timeout=900,\n",
        "    cpu_limit=2,\n",
        "    gpu_ids='0',\n",
        "    general_params={\n",
        "        'nested_cv': False,\n",
        "        'use_algos': [['nn']]\n",
        "    },\n",
        "    autonlp_params={\n",
        "        'sent_scaler': 'l2'\n",
        "    },\n",
        "    text_params={\n",
        "        'lang': 'en',\n",
        "        'bert_model': 'prajjwal1/bert-tiny'\n",
        "    },\n",
        "    nn_params={\n",
        "        'opt_params': {'lr': 1e-5},\n",
        "        'max_length': 128,\n",
        "        'bs': 32,\n",
        "        'n_epochs': 2,\n",
        "    }\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "868f6f78-94fb-4339-fa81-e3700db92cfe",
        "id": "0U81vxqVKm3m"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:30:24] Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:30:24] Model language mode: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.automl.presets.text_presets:Model language mode: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:30:24] Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:30:24] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:30:24] - time: 900.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 900.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:30:24] - CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:30:24] - memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:30:24] \u001b[1mTrain data shape: (127656, 8)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (127656, 8)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:30:24] Layer \u001b[1m1\u001b[0m train process start. Time left 899.91 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 899.91 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:30:24] number of text features: 1 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of text features: 1 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:30:24] number of categorical features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of categorical features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:30:24] number of continuous features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of continuous features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:30:24] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:30:24] Training params: {'num_workers': 2, 'pin_memory': False, 'max_length': 128, 'is_snap': False, 'input_bn': False, 'max_emb_size': 50, 'bert_name': 'prajjwal1/bert-tiny', 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': False, 'multigpu': False, 'random_state': 42, 'model': '_linear_layer', 'model_with_emb': False, 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 1, 'early_stopping': True, 'patience': 1, 'swa': False}, 'bs': 32, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'lr': 1e-05}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 5, 'factor': 0.5, 'verbose': True}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'optimization_search_space': None, 'verbose_bar': False, 'freeze_defaults': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'embedding_size': 10, 'cat_embedder': 'cat', 'cont_embedder': 'cont', 'stop_by_metric': False, 'device_ids': None, 'num_dims': 0, 'text_features': ['concated__comment_text'], 'bias': array([-2.88797639])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.base:Training params: {'num_workers': 2, 'pin_memory': False, 'max_length': 128, 'is_snap': False, 'input_bn': False, 'max_emb_size': 50, 'bert_name': 'prajjwal1/bert-tiny', 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': False, 'multigpu': False, 'random_state': 42, 'model': '_linear_layer', 'model_with_emb': False, 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 1, 'early_stopping': True, 'patience': 1, 'swa': False}, 'bs': 32, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'lr': 1e-05}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 5, 'factor': 0.5, 'verbose': True}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'optimization_search_space': None, 'verbose_bar': False, 'freeze_defaults': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'embedding_size': 10, 'cat_embedder': 'cat', 'cont_embedder': 'cont', 'stop_by_metric': False, 'device_ids': None, 'num_dims': 0, 'text_features': ['concated__comment_text'], 'bias': array([-2.88797639])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:30:24] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:30:25] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:34:03] Epoch: 0, train loss: 0.6797207593917847, val loss: 0.5718210935592651, val metric: 0.966413324398566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: 0.6797207593917847, val loss: 0.5718210935592651, val metric: 0.966413324398566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:37:40] Epoch: 1, train loss: 0.6129001975059509, val loss: 0.5596133470535278, val metric: 0.9784126132522889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 1, train loss: 0.6129001975059509, val loss: 0.5596133470535278, val metric: 0.9784126132522889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:37:41] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:37:41] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:41:20] Epoch: 0, train loss: 0.6775449514389038, val loss: 0.5558379292488098, val metric: 0.9635759686941698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: 0.6775449514389038, val loss: 0.5558379292488098, val metric: 0.9635759686941698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:44:56] Epoch: 1, train loss: 0.611206591129303, val loss: 0.5720446109771729, val metric: 0.9740437796924197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 1, train loss: 0.611206591129303, val loss: 0.5720446109771729, val metric: 0.9740437796924197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:44:57] Time limit exceeded after calculating fold 1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:44:57] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m finished. score = \u001b[1m0.9760937854290586\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m finished. score = \u001b[1m0.9760937854290586\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:44:57] \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:44:57] Time left 26.84 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 26.84 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:44:57] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:44:57] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:44:57] \u001b[1mAutoml preset training completed in 873.18 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 873.18 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:44:57] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:44:58] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:45:48] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:46:39] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:50:28] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check scores:\n",
            "OOF score: 0.9760937854290586\n",
            "TEST score: 0.9712044388237793\n",
            "CPU times: user 4min 26s, sys: 17.5 s, total: 4min 44s\n",
            "Wall time: 23min 54s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "oof_pred_obscene = automl_obscene.fit_predict(train, roles=roles, verbose = 10)\n",
        "test_pred_obscene = automl_obscene.predict(test)\n",
        "not_nan = np.any(~np.isnan(oof_pred_obscene.data), axis=1)\n",
        "\n",
        "sumb_obscene = automl_obscene.predict(subm)\n",
        "\n",
        "print('Check scores:')\n",
        "print('OOF score: {}'.format(roc_auc_score(train[roles['target']].values[not_nan], oof_pred_obscene.data[not_nan][:, 0])))\n",
        "print('TEST score: {}'.format(roc_auc_score(test[roles['target']].values, test_pred_obscene.data[:, 0])))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(sumb_obscene.data).to_csv('sumb_obscene.csv', index=False)"
      ],
      "metadata": {
        "id": "sjwJGD-Sd0TG"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDDQY9DvLaKy"
      },
      "source": [
        "### Insult model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "2lWOWReJLaK1"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "roles = {\n",
        "    'text': ['comment_text'],\n",
        "    'drop': ['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'identity_hate'],\n",
        "    'target': 'insult'\n",
        "}\n",
        "\n",
        "task = Task('binary')\n",
        "\n",
        "automl_insult = TabularNLPAutoML(\n",
        "    task=task,\n",
        "    timeout=900,\n",
        "    cpu_limit=2,\n",
        "    gpu_ids='0',\n",
        "    general_params={\n",
        "        'nested_cv': False,\n",
        "        'use_algos': [['nn']]\n",
        "    },\n",
        "    autonlp_params={\n",
        "        'sent_scaler': 'l2'\n",
        "    },\n",
        "    text_params={\n",
        "        'lang': 'en',\n",
        "        'bert_model': 'prajjwal1/bert-tiny'\n",
        "    },\n",
        "    nn_params={\n",
        "        'opt_params': {'lr': 1e-5},\n",
        "        'max_length': 128,\n",
        "        'bs': 32,\n",
        "        'n_epochs': 1,\n",
        "    }\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c72f77a-3411-49c8-8d1a-3359140f2274",
        "id": "59ThF4kKLaK2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:07:33] Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:07:33] Model language mode: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.automl.presets.text_presets:Model language mode: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:07:33] Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:07:33] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:07:33] - time: 900.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 900.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:07:33] - CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:07:33] - memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:07:33] \u001b[1mTrain data shape: (127656, 8)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (127656, 8)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:07:33] Layer \u001b[1m1\u001b[0m train process start. Time left 899.92 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 899.92 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:07:33] number of text features: 1 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of text features: 1 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:07:33] number of categorical features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of categorical features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:07:33] number of continuous features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of continuous features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:07:33] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:07:33] Training params: {'num_workers': 2, 'pin_memory': False, 'max_length': 128, 'is_snap': False, 'input_bn': False, 'max_emb_size': 50, 'bert_name': 'prajjwal1/bert-tiny', 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': False, 'multigpu': False, 'random_state': 42, 'model': '_linear_layer', 'model_with_emb': False, 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 1, 'snap_params': {'k': 1, 'early_stopping': True, 'patience': 1, 'swa': False}, 'bs': 32, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'lr': 1e-05}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 5, 'factor': 0.5, 'verbose': True}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'optimization_search_space': None, 'verbose_bar': False, 'freeze_defaults': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'embedding_size': 10, 'cat_embedder': 'cat', 'cont_embedder': 'cont', 'stop_by_metric': False, 'device_ids': None, 'num_dims': 0, 'text_features': ['concated__comment_text'], 'bias': array([-2.96437391])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.base:Training params: {'num_workers': 2, 'pin_memory': False, 'max_length': 128, 'is_snap': False, 'input_bn': False, 'max_emb_size': 50, 'bert_name': 'prajjwal1/bert-tiny', 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': False, 'multigpu': False, 'random_state': 42, 'model': '_linear_layer', 'model_with_emb': False, 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 1, 'snap_params': {'k': 1, 'early_stopping': True, 'patience': 1, 'swa': False}, 'bs': 32, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'lr': 1e-05}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 5, 'factor': 0.5, 'verbose': True}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'optimization_search_space': None, 'verbose_bar': False, 'freeze_defaults': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'embedding_size': 10, 'cat_embedder': 'cat', 'cont_embedder': 'cont', 'stop_by_metric': False, 'device_ids': None, 'num_dims': 0, 'text_features': ['concated__comment_text'], 'bias': array([-2.96437391])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:07:33] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:07:34] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:11:31] Epoch: 0, train loss: 0.6952386498451233, val loss: 0.5775730013847351, val metric: 0.9512137205181429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: 0.6952386498451233, val loss: 0.5775730013847351, val metric: 0.9512137205181429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:11:31] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:11:32] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:15:23] Epoch: 0, train loss: 0.6960780024528503, val loss: 0.600500762462616, val metric: 0.9552506714733611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: 0.6960780024528503, val loss: 0.600500762462616, val metric: 0.9552506714733611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:15:23] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:15:24] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:32] Epoch: 0, train loss: 0.695831835269928, val loss: 0.6240615844726562, val metric: 0.953731097856815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: 0.695831835269928, val loss: 0.6240615844726562, val metric: 0.953731097856815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:33] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m finished. score = \u001b[1m0.9526995300188728\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m finished. score = \u001b[1m0.9526995300188728\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:33] \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:33] Time left 180.06 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 180.06 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:33] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:33] \u001b[1mAutoml preset training completed in 719.96 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 719.96 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:33] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 1.00000 * (3 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 1.00000 * (3 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:19:34] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:20:34] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:30] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:22:21] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:26:28] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:31:20] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check scores:\n",
            "OOF score: 0.9526995300188728\n",
            "TEST score: 0.9524418201075233\n",
            "CPU times: user 4min 12s, sys: 19 s, total: 4min 31s\n",
            "Wall time: 28min 24s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "oof_pred_insult = automl_insult.fit_predict(train, roles=roles, verbose = 10)\n",
        "test_pred_insult = automl_insult.predict(test)\n",
        "not_nan = np.any(~np.isnan(oof_pred_insult.data), axis=1)\n",
        "\n",
        "sumb_insult = automl_insult.predict(subm)\n",
        "\n",
        "\n",
        "print('Check scores:')\n",
        "print('OOF score: {}'.format(roc_auc_score(train[roles['target']].values[not_nan], oof_pred_insult.data[not_nan][:, 0])))\n",
        "print('TEST score: {}'.format(roc_auc_score(test[roles['target']].values, test_pred_insult.data[:, 0])))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(sumb_insult.data).to_csv('sumb_insult.csv', index=False)"
      ],
      "metadata": {
        "id": "KT1c0LhnMIhW"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUcOa5HJO43B"
      },
      "source": [
        "### Identity_hate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "NwUffwp_O43G"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "roles = {\n",
        "    'text': ['comment_text'],\n",
        "    'drop': ['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult'],\n",
        "    'target': 'identity_hate'\n",
        "}\n",
        "\n",
        "task = Task('binary')\n",
        "\n",
        "automl_identity_hate = TabularNLPAutoML(\n",
        "    task=task,\n",
        "    timeout=900,\n",
        "    cpu_limit=2,\n",
        "    gpu_ids='0',\n",
        "    general_params={\n",
        "        'nested_cv': False,\n",
        "        'use_algos': [['nn']]\n",
        "    },\n",
        "    autonlp_params={\n",
        "        'sent_scaler': 'l2'\n",
        "    },\n",
        "    text_params={\n",
        "        'lang': 'en',\n",
        "        'bert_model': 'prajjwal1/bert-tiny'\n",
        "    },\n",
        "    nn_params={\n",
        "        'opt_params': {'lr': 1e-5},\n",
        "        'max_length': 128,\n",
        "        'bs': 32,\n",
        "        'n_epochs': 1,\n",
        "    }\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7230c522-58de-44ae-9965-21271d8815d4",
        "id": "XIucH9iWO43H"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:58] Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:58] Model language mode: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.automl.presets.text_presets:Model language mode: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:58] Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:58] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:58] - time: 900.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 900.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:58] - CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:58] - memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:58] \u001b[1mTrain data shape: (127656, 8)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (127656, 8)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:58] Layer \u001b[1m1\u001b[0m train process start. Time left 899.92 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 899.92 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:58] number of text features: 1 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of text features: 1 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:58] number of categorical features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of categorical features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:58] number of continuous features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of continuous features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:58] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:58] Training params: {'num_workers': 2, 'pin_memory': False, 'max_length': 128, 'is_snap': False, 'input_bn': False, 'max_emb_size': 50, 'bert_name': 'prajjwal1/bert-tiny', 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': False, 'multigpu': False, 'random_state': 42, 'model': '_linear_layer', 'model_with_emb': False, 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 1, 'snap_params': {'k': 1, 'early_stopping': True, 'patience': 1, 'swa': False}, 'bs': 32, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'lr': 1e-05}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 5, 'factor': 0.5, 'verbose': True}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'optimization_search_space': None, 'verbose_bar': False, 'freeze_defaults': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'embedding_size': 10, 'cat_embedder': 'cat', 'cont_embedder': 'cont', 'stop_by_metric': False, 'device_ids': None, 'num_dims': 0, 'text_features': ['concated__comment_text'], 'bias': array([-4.73533747])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.base:Training params: {'num_workers': 2, 'pin_memory': False, 'max_length': 128, 'is_snap': False, 'input_bn': False, 'max_emb_size': 50, 'bert_name': 'prajjwal1/bert-tiny', 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': False, 'multigpu': False, 'random_state': 42, 'model': '_linear_layer', 'model_with_emb': False, 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 1, 'snap_params': {'k': 1, 'early_stopping': True, 'patience': 1, 'swa': False}, 'bs': 32, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'lr': 1e-05}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 5, 'factor': 0.5, 'verbose': True}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'optimization_search_space': None, 'verbose_bar': False, 'freeze_defaults': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'embedding_size': 10, 'cat_embedder': 'cat', 'cont_embedder': 'cont', 'stop_by_metric': False, 'device_ids': None, 'num_dims': 0, 'text_features': ['concated__comment_text'], 'bias': array([-4.73533747])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:58] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:35:59] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:39:39] Epoch: 0, train loss: 0.7784637212753296, val loss: 0.6959517598152161, val metric: 0.9399264704940111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: 0.7784637212753296, val loss: 0.6959517598152161, val metric: 0.9399264704940111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:39:39] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:39:40] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:43:36] Epoch: 0, train loss: 0.7803735136985779, val loss: 0.6741276383399963, val metric: 0.9393030779107778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: 0.7803735136985779, val loss: 0.6741276383399963, val metric: 0.9393030779107778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:43:37] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:43:37] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:36] Epoch: 0, train loss: 0.7776265740394592, val loss: 0.7059352993965149, val metric: 0.9409647846071648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: 0.7776265740394592, val loss: 0.7059352993965149, val metric: 0.9409647846071648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:36] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m finished. score = \u001b[1m0.9397952628642294\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m finished. score = \u001b[1m0.9397952628642294\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:36] \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:36] Time left 201.48 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 201.48 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:36] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:36] \u001b[1mAutoml preset training completed in 698.54 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 698.54 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:36] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 1.00000 * (3 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 1.00000 * (3 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:47:37] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:48:43] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:49:48] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:51:05] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:54:59] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:58:50] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check scores:\n",
            "OOF score: 0.9397952628642294\n",
            "TEST score: 0.9331304736562094\n",
            "CPU times: user 4min 9s, sys: 18.9 s, total: 4min 28s\n",
            "Wall time: 26min 45s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "oof_pred_identity_hate = automl_identity_hate.fit_predict(train, roles=roles, verbose = 10)\n",
        "test_pred_identity_hate = automl_identity_hate.predict(test)\n",
        "not_nan = np.any(~np.isnan(oof_pred_identity_hate.data), axis=1)\n",
        "\n",
        "sumb_identity_hate = automl_identity_hate.predict(subm)\n",
        "\n",
        "print('Check scores:')\n",
        "print('OOF score: {}'.format(roc_auc_score(train[roles['target']].values[not_nan], oof_pred_identity_hate.data[not_nan][:, 0])))\n",
        "print('TEST score: {}'.format(roc_auc_score(test[roles['target']].values, test_pred_identity_hate.data[:, 0])))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(sumb_identity_hate.data).to_csv('sumb_identity_hate.csv', index=False)"
      ],
      "metadata": {
        "id": "9ecStDLCO43I"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yE0C-xvbTzxC"
      },
      "source": [
        "### Threat model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "qbbX3xR3TzxE"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "roles = {\n",
        "    'text': ['comment_text'],\n",
        "    'drop': ['id', 'toxic', 'severe_toxic', 'obscene', 'identity_hate', 'insult'],\n",
        "    'target': 'threat'\n",
        "}\n",
        "\n",
        "task = Task('binary')\n",
        "\n",
        "automl_threat = TabularNLPAutoML(\n",
        "    task=task,\n",
        "    timeout=900,\n",
        "    cpu_limit=2,\n",
        "    gpu_ids='0',\n",
        "    general_params={\n",
        "        'nested_cv': False,\n",
        "        'use_algos': [['nn']]\n",
        "    },\n",
        "    autonlp_params={\n",
        "        'sent_scaler': 'l2'\n",
        "    },\n",
        "    text_params={\n",
        "        'lang': 'en',\n",
        "        'bert_model': 'prajjwal1/bert-tiny'\n",
        "    },\n",
        "    nn_params={\n",
        "        'opt_params': {'lr': 1e-5},\n",
        "        'max_length': 128,\n",
        "        'bs': 32,\n",
        "        'n_epochs': 1,\n",
        "    }\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1Eh4Ax3TzxF",
        "outputId": "63af6287-4ff1-4c63-be29-e01cf6445d85"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:02:43] Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:02:43] Model language mode: en\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO3:lightautoml.automl.presets.text_presets:Model language mode: en\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:02:43] Task: binary\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: binary\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:02:43] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:02:43] - time: 900.00 seconds\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 900.00 seconds\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:02:43] - CPU: 2 cores\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 2 cores\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:02:43] - memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:02:43] \u001b[1mTrain data shape: (127656, 8)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (127656, 8)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:02:43] Layer \u001b[1m1\u001b[0m train process start. Time left 899.92 secs\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 899.92 secs\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:02:44] number of text features: 1 \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of text features: 1 \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:02:44] number of categorical features: 0 \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of categorical features: 0 \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:02:44] number of continuous features: 0 \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of continuous features: 0 \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:02:44] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:02:44] Training params: {'num_workers': 2, 'pin_memory': False, 'max_length': 128, 'is_snap': False, 'input_bn': False, 'max_emb_size': 50, 'bert_name': 'prajjwal1/bert-tiny', 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': False, 'multigpu': False, 'random_state': 42, 'model': '_linear_layer', 'model_with_emb': False, 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 1, 'snap_params': {'k': 1, 'early_stopping': True, 'patience': 1, 'swa': False}, 'bs': 32, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'lr': 1e-05}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 5, 'factor': 0.5, 'verbose': True}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'optimization_search_space': None, 'verbose_bar': False, 'freeze_defaults': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'embedding_size': 10, 'cat_embedder': 'cat', 'cont_embedder': 'cont', 'stop_by_metric': False, 'device_ids': None, 'num_dims': 0, 'text_features': ['concated__comment_text'], 'bias': array([-5.75250977])}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:lightautoml.ml_algo.base:Training params: {'num_workers': 2, 'pin_memory': False, 'max_length': 128, 'is_snap': False, 'input_bn': False, 'max_emb_size': 50, 'bert_name': 'prajjwal1/bert-tiny', 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': False, 'multigpu': False, 'random_state': 42, 'model': '_linear_layer', 'model_with_emb': False, 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 1, 'snap_params': {'k': 1, 'early_stopping': True, 'patience': 1, 'swa': False}, 'bs': 32, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'lr': 1e-05}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 5, 'factor': 0.5, 'verbose': True}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'optimization_search_space': None, 'verbose_bar': False, 'freeze_defaults': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'embedding_size': 10, 'cat_embedder': 'cat', 'cont_embedder': 'cont', 'stop_by_metric': False, 'device_ids': None, 'num_dims': 0, 'text_features': ['concated__comment_text'], 'bias': array([-5.75250977])}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:02:44] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:02:44] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:06:21] Epoch: 0, train loss: 0.7895164489746094, val loss: 0.6870625615119934, val metric: 0.930821134790004\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: 0.7895164489746094, val loss: 0.6870625615119934, val metric: 0.930821134790004\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:06:22] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:06:23] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:10:01] Epoch: 0, train loss: 0.7894597053527832, val loss: 0.7486295104026794, val metric: 0.9032832747876246\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: 0.7894597053527832, val loss: 0.7486295104026794, val metric: 0.9032832747876246\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:10:02] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:10:03] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:13:40] Epoch: 0, train loss: 0.7903108596801758, val loss: 0.7048534750938416, val metric: 0.9323143498544869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: 0.7903108596801758, val loss: 0.7048534750938416, val metric: 0.9323143498544869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:13:41] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m finished. score = \u001b[1m0.9191410323882166\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m finished. score = \u001b[1m0.9191410323882166\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:13:41] \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:13:41] Time left 242.29 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 242.29 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:13:41] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:13:41] \u001b[1mAutoml preset training completed in 657.72 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 657.72 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:13:41] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 1.00000 * (3 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 1.00000 * (3 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:13:42] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:14:33] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:15:23] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:16:15] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:20:07] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:23:58] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check scores:\n",
            "OOF score: 0.9191410323882166\n",
            "TEST score: 0.9314079161916855\n",
            "CPU times: user 4min 7s, sys: 18.3 s, total: 4min 25s\n",
            "Wall time: 25min 3s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "oof_pred_threat = automl_threat.fit_predict(train, roles=roles, verbose = 10)\n",
        "test_pred_threat = automl_threat.predict(test)\n",
        "not_nan = np.any(~np.isnan(oof_pred_threat.data), axis=1)\n",
        "\n",
        "sumb_threat = automl_threat.predict(subm)\n",
        "\n",
        "print('Check scores:')\n",
        "print('OOF score: {}'.format(roc_auc_score(train[roles['target']].values[not_nan], oof_pred_threat.data[not_nan][:, 0])))\n",
        "print('TEST score: {}'.format(roc_auc_score(test[roles['target']].values, test_pred_threat.data[:, 0])))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(sumb_threat.data).to_csv('sumb_threat.csv', index=False)"
      ],
      "metadata": {
        "id": "vw1sb8MaTzxF"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merge subm"
      ],
      "metadata": {
        "id": "6a_rhHzPldzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "result['threat'] = sumb_threat.data\n",
        "result['severe_toxic'] = sumb_severe_toxic.data\n",
        "result['toxic'] = sumb_toxic.data\n",
        "result['obscene'] = sumb_obscene.data\n",
        "result['insult'] = sumb_insult.data\n",
        "result['identity_hate'] = sumb_identity_hate.data\n",
        "\n",
        "result.to_csv('sumb_binary.csv', index=False)"
      ],
      "metadata": {
        "id": "nGFm0Fk4ll63"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MmKChkJ0veQo",
        "outputId": "80d104f7-19e4-4f40-bc61-d32285e50fee"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
              "0  00001cee341fdb12  0.991064      0.995989  0.992621  0.827358  0.996373   \n",
              "1  0000247867823ef7  0.407244      0.435450  0.431209  0.407637  0.438429   \n",
              "2  00013b17ad220c46  0.447829      0.435964  0.454814  0.351706  0.441151   \n",
              "3  00017563c3f7919a  0.381211      0.437420  0.414000  0.408708  0.413102   \n",
              "4  00017695ad8997eb  0.422219      0.447269  0.435335  0.434344  0.452779   \n",
              "\n",
              "   identity_hate  \n",
              "0       0.998123  \n",
              "1       0.381124  \n",
              "2       0.349259  \n",
              "3       0.441688  \n",
              "4       0.469081  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21b04525-8e95-4c30-97db-49390fdc97fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>0.991064</td>\n",
              "      <td>0.995989</td>\n",
              "      <td>0.992621</td>\n",
              "      <td>0.827358</td>\n",
              "      <td>0.996373</td>\n",
              "      <td>0.998123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>0.407244</td>\n",
              "      <td>0.435450</td>\n",
              "      <td>0.431209</td>\n",
              "      <td>0.407637</td>\n",
              "      <td>0.438429</td>\n",
              "      <td>0.381124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>0.447829</td>\n",
              "      <td>0.435964</td>\n",
              "      <td>0.454814</td>\n",
              "      <td>0.351706</td>\n",
              "      <td>0.441151</td>\n",
              "      <td>0.349259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>0.381211</td>\n",
              "      <td>0.437420</td>\n",
              "      <td>0.414000</td>\n",
              "      <td>0.408708</td>\n",
              "      <td>0.413102</td>\n",
              "      <td>0.441688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>0.422219</td>\n",
              "      <td>0.447269</td>\n",
              "      <td>0.435335</td>\n",
              "      <td>0.434344</td>\n",
              "      <td>0.452779</td>\n",
              "      <td>0.469081</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21b04525-8e95-4c30-97db-49390fdc97fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-21b04525-8e95-4c30-97db-49390fdc97fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-21b04525-8e95-4c30-97db-49390fdc97fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3fb65ee7-1600-4224-a6ba-86dfc9ef168f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3fb65ee7-1600-4224-a6ba-86dfc9ef168f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3fb65ee7-1600-4224-a6ba-86dfc9ef168f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nFqmpEw39xoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automl multilabels"
      ],
      "metadata": {
        "id": "9qZw1kMTRjDw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifOoFlJSRjD1",
        "outputId": "83860ebf-2fb1-462e-b926-8cbfa931b176"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "multilabel isn`t supported in lgb\n",
            "[15:31:07] CatBoost uses as obj. MultiCrossEntropy.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.tasks.losses.cb:CatBoost uses as obj. MultiCrossEntropy.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "multilabel isn`t supported in xgb\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "roles = {\n",
        "    'text': ['comment_text'],\n",
        "    'drop': ['id'],\n",
        "    'target': ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "}\n",
        "\n",
        "task = Task('multilabel')\n",
        "\n",
        "automl = TabularNLPAutoML(\n",
        "    task=task,\n",
        "    timeout=900,\n",
        "    cpu_limit=2,\n",
        "    gpu_ids='0',\n",
        "    general_params={\n",
        "        'nested_cv': False,\n",
        "        'use_algos': [['nn']]\n",
        "    },\n",
        "    autonlp_params={\n",
        "        'sent_scaler': 'l2'\n",
        "    },\n",
        "    text_params={\n",
        "        'lang': 'en',\n",
        "        'bert_model': 'prajjwal1/bert-tiny'\n",
        "    },\n",
        "    nn_params={\n",
        "        'opt_params': {'lr': 1e-5},\n",
        "        'max_length': 128,\n",
        "        'bs': 32,\n",
        "        'n_epochs': 2,\n",
        "    }\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a19cf21f-3c8a-4e70-b667-334404a88e07",
        "id": "D1nEHZF_RjD1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:31:12] Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is DEBUG.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:31:12] Model language mode: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.automl.presets.text_presets:Model language mode: en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:31:12] Task: multilabel\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: multilabel\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:31:12] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:31:12] - time: 900.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 900.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:31:12] - CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:31:12] - memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:31:12] \u001b[1mTrain data shape: (127656, 8)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (127656, 8)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:31:12] Layer \u001b[1m1\u001b[0m train process start. Time left 899.93 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 899.93 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:31:13] number of text features: 1 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of text features: 1 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:31:13] number of categorical features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of categorical features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:31:13] number of continuous features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.dl_model:number of continuous features: 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:31:13] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:31:13] Training params: {'num_workers': 2, 'pin_memory': False, 'max_length': 128, 'is_snap': False, 'input_bn': False, 'max_emb_size': 50, 'bert_name': 'prajjwal1/bert-tiny', 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': False, 'multigpu': False, 'random_state': 42, 'model': '_linear_layer', 'model_with_emb': False, 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 1, 'early_stopping': True, 'patience': 1, 'swa': False}, 'bs': 32, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'lr': 1e-05}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 5, 'factor': 0.5, 'verbose': True}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'optimization_search_space': None, 'verbose_bar': False, 'freeze_defaults': False, 'n_out': 6, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'embedding_size': 10, 'cat_embedder': 'cat', 'cont_embedder': 'cont', 'stop_by_metric': False, 'device_ids': None, 'num_dims': 0, 'text_features': ['concated__comment_text'], 'bias': array([-2.24401446, -4.59714751, -2.88797639, -5.75250977, -2.96437391,\n",
            "       -4.73533747])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:lightautoml.ml_algo.base:Training params: {'num_workers': 2, 'pin_memory': False, 'max_length': 128, 'is_snap': False, 'input_bn': False, 'max_emb_size': 50, 'bert_name': 'prajjwal1/bert-tiny', 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': False, 'multigpu': False, 'random_state': 42, 'model': '_linear_layer', 'model_with_emb': False, 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 1, 'early_stopping': True, 'patience': 1, 'swa': False}, 'bs': 32, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'lr': 1e-05}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 5, 'factor': 0.5, 'verbose': True}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'optimization_search_space': None, 'verbose_bar': False, 'freeze_defaults': False, 'n_out': 6, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'embedding_size': 10, 'cat_embedder': 'cat', 'cont_embedder': 'cont', 'stop_by_metric': False, 'device_ids': None, 'num_dims': 0, 'text_features': ['concated__comment_text'], 'bias': array([-2.24401446, -4.59714751, -2.88797639, -5.75250977, -2.96437391,\n",
            "       -4.73533747])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:31:13] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:31:14] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:35:19] Epoch: 0, train loss: 4.403194427490234, val loss: 3.86201548576355, val metric: -0.0545819964415064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: 4.403194427490234, val loss: 3.86201548576355, val metric: -0.0545819964415064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:39:33] Epoch: 1, train loss: 4.092041492462158, val loss: 3.868513822555542, val metric: -0.04869413448902502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "INFO3:lightautoml.text.trainer:Epoch: 1, train loss: 4.092041492462158, val loss: 3.868513822555542, val metric: -0.04869413448902502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:39:33] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:39:34] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:43:22] Epoch: 0, train loss: 4.4016852378845215, val loss: 3.8507299423217773, val metric: -0.045373171884618035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: 4.4016852378845215, val loss: 3.8507299423217773, val metric: -0.045373171884618035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:47:04] Epoch: 1, train loss: 4.0943603515625, val loss: 3.7251954078674316, val metric: -0.04070881142414933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "INFO3:lightautoml.text.trainer:Epoch: 1, train loss: 4.0943603515625, val loss: 3.7251954078674316, val metric: -0.04070881142414933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:47:05] Time limit exceeded after calculating fold 1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:47:05] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m finished. score = \u001b[1m-0.044701472956587184\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n",
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m finished. score = \u001b[1m-0.044701472956587184\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:47:05] \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:47:05] Time left -53.23 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left -53.23 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:47:05] Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:47:05] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:47:05] \u001b[1mAutoml preset training completed in 953.24 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 953.24 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:47:05] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN__linear_layer_0) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:47:06] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:48:02] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:48:54] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:52:50] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4min 31s, sys: 18.3 s, total: 4min 49s\n",
            "Wall time: 25min 28s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "oof_pred = automl.fit_predict(train, roles=roles, verbose = 10)\n",
        "test_pred = automl.predict(test)\n",
        "not_nan = np.any(~np.isnan(oof_pred.data), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sumb_miltilabels = automl.predict(subm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWQDAD4V5qPm",
        "outputId": "26cc4a83-8498-40cc-9e9f-85890727eaa4"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16:02:53] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16:06:49] Last linear layer not founded, so init_bias=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.text.nn_model:Last linear layer not founded, so init_bias=False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sumb_miltilabels.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-uEwhON4Z_x",
        "outputId": "8aea926a-8c35-4524-ac7a-cf4604dfc349"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9828239 , 0.9846284 , 0.98962   , 0.49833217, 0.9837056 ,\n",
              "        0.9787377 ],\n",
              "       [0.37272438, 0.4439507 , 0.41867036, 0.4061284 , 0.41787496,\n",
              "        0.4060862 ],\n",
              "       [0.43483812, 0.44307137, 0.39727253, 0.48903686, 0.40749156,\n",
              "        0.38027114],\n",
              "       ...,\n",
              "       [0.38034922, 0.41815567, 0.4196272 , 0.41462255, 0.4049163 ,\n",
              "        0.36485583],\n",
              "       [0.3572696 , 0.41791344, 0.40526015, 0.47089985, 0.39995384,\n",
              "        0.38802055],\n",
              "       [0.980477  , 0.9126931 , 0.967576  , 0.56080574, 0.9613559 ,\n",
              "        0.9562428 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "result[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']] = sumb_miltilabels.data\n",
        "\n",
        "result.to_csv('sumb_miltilabels.csv', index=False)"
      ],
      "metadata": {
        "id": "Crf7yDNqyxmn"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic regression with TF-IDF"
      ],
      "metadata": {
        "id": "n5813JR5g1ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ],
      "metadata": {
        "id": "tt1Al6RChRgX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "subm = pd.read_csv('sample_submission.csv')"
      ],
      "metadata": {
        "id": "nWZKlFpkhSRC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "train['none'] = 1-train[label_cols].max(axis=1)"
      ],
      "metadata": {
        "id": "ycFa-aKID1MZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COMMENT = 'comment_text'\n",
        "train[COMMENT].fillna(\"unknown\", inplace=True)\n",
        "test[COMMENT].fillna(\"unknown\", inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR0Jwrpohejn",
        "outputId": "e31dc72d-48d3-4bbc-e74e-8af8e4dff947"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-d2957acc749a>:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train[COMMENT].fillna(\"unknown\", inplace=True)\n",
            "<ipython-input-8-d2957acc749a>:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  test[COMMENT].fillna(\"unknown\", inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re, string\n",
        "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
        "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()"
      ],
      "metadata": {
        "id": "0wsj1HNuhgSh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = train.shape[0]\n",
        "vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
        "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=True,\n",
        "               smooth_idf=True, sublinear_tf=True )\n",
        "trn_term_doc = vec.fit_transform(train[COMMENT])\n",
        "test_term_doc = vec.transform(test[COMMENT])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pIIslYzhibM",
        "outputId": "a135f22e-452a-4beb-ff0a-55d1630eb0a9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trn_term_doc, test_term_doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjQQpQBIhko-",
        "outputId": "bd39c1f7-e3da-4f6e-e3b2-ff8c21cca1c2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<159571x426005 sparse matrix of type '<class 'numpy.float64'>'\n",
              " \twith 17775119 stored elements in Compressed Sparse Row format>,\n",
              " <153164x426005 sparse matrix of type '<class 'numpy.float64'>'\n",
              " \twith 14765768 stored elements in Compressed Sparse Row format>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pr(y_i, y):\n",
        "    p = x[y==y_i].sum(0)\n",
        "    return (p+1) / ((y==y_i).sum()+1)"
      ],
      "metadata": {
        "id": "9xLgLEWsh9vP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = trn_term_doc\n",
        "test_x = test_term_doc"
      ],
      "metadata": {
        "id": "yo2Fgzg4h-_b"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mdl(y):\n",
        "    y = y.values\n",
        "    r = np.log(pr(1,y) / pr(0,y))\n",
        "    m = LogisticRegression(C=4, dual=False)\n",
        "    x_nb = x.multiply(r)\n",
        "    return m.fit(x_nb, y), r"
      ],
      "metadata": {
        "id": "tgXrP2Y5iAs9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.zeros((len(test), len(label_cols)))\n",
        "\n",
        "for i, j in enumerate(label_cols):\n",
        "    print('fit', j)\n",
        "    m,r = get_mdl(train[j])\n",
        "    preds[:,i] = m.predict_proba(test_x.multiply(r))[:,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYSmea-QiCZ5",
        "outputId": "10abb2d4-5b65-4838-f362-d5c0098ebb36"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit toxic\n",
            "fit severe_toxic\n",
            "fit obscene\n",
            "fit threat\n",
            "fit insult\n",
            "fit identity_hate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submid = pd.DataFrame({'id': subm[\"id\"]})\n",
        "submission = pd.concat([submid, pd.DataFrame(preds, columns = label_cols)], axis=1)\n",
        "submission.to_csv('submission_tdidf.csv', index=False)"
      ],
      "metadata": {
        "id": "tHeFXg17iEdi"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic regression with n-grams"
      ],
      "metadata": {
        "id": "t_tYoNRVjkHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from scipy.sparse import hstack"
      ],
      "metadata": {
        "id": "F7imnx6jjg4f"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv').fillna(' ')\n",
        "test = pd.read_csv('test.csv').fillna(' ')"
      ],
      "metadata": {
        "id": "jLhN0qFvlFRv"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text = train['comment_text']\n",
        "test_text = test['comment_text']\n",
        "all_text = pd.concat([train_text, test_text])"
      ],
      "metadata": {
        "id": "gTDw_x7xlDKE"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='word',\n",
        "    token_pattern=r'\\w{1,}',\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 1),\n",
        "    max_features=10000)\n",
        "word_vectorizer.fit(all_text)\n",
        "train_word_features = word_vectorizer.transform(train_text)\n",
        "test_word_features = word_vectorizer.transform(test_text)\n",
        "\n",
        "char_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='char',\n",
        "    stop_words='english',\n",
        "    ngram_range=(2, 6),\n",
        "    max_features=50000)\n",
        "char_vectorizer.fit(all_text)\n",
        "\n",
        "train_char_features = char_vectorizer.transform(train_text)\n",
        "test_char_features = char_vectorizer.transform(test_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxYwhRmzkoYG",
        "outputId": "71a4a366-7b49-4df1-f3f4-8b6ee3f1b9fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:539: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = hstack([train_char_features, train_word_features])\n",
        "test_features = hstack([test_char_features, test_word_features])"
      ],
      "metadata": {
        "id": "MOz2IxWnkoec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
        "for class_name in label_cols:\n",
        "    train_target = train[class_name]\n",
        "    classifier = LogisticRegression(C=0.1, solver='sag')\n",
        "\n",
        "    cv_score = np.mean(cross_val_score(classifier, train_features, train_target, cv=3, scoring='roc_auc'))\n",
        "    scores.append(cv_score)\n",
        "\n",
        "    classifier.fit(train_features, train_target)\n",
        "    submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
        "\n",
        "submission.to_csv('submission_n_grams.csv', index=False)"
      ],
      "metadata": {
        "id": "ZbF8qn6UkoPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b_70mCGNH0zp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "my_jup_kernel",
      "language": "python",
      "name": "my_jup_kernel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "77738023c946bcedeeb6a5c983bcfb7849325694ebd87acbc9267f45e9f4af48"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dc8353c177f64d82857ea915eca27d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcdfba5a26e84f2a9ffc7193f3d9b1f4",
              "IPY_MODEL_985b563f947d4389b363b8edd398e26b",
              "IPY_MODEL_7db35c0980234888beb9e31dc4d508fc"
            ],
            "layout": "IPY_MODEL_44e01017275c4e23b036424c61c336fc"
          }
        },
        "bcdfba5a26e84f2a9ffc7193f3d9b1f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_962270b3f0aa47b88265a4982aa1d0e6",
            "placeholder": "​",
            "style": "IPY_MODEL_a1a52213370143a2867c7f55369f6f59",
            "value": "config.json: 100%"
          }
        },
        "985b563f947d4389b363b8edd398e26b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d8adce041264808ab961843960dc9f7",
            "max": 285,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_239a76d1404346a4b0a4b2e12dbc92f1",
            "value": 285
          }
        },
        "7db35c0980234888beb9e31dc4d508fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad97b62eda2747688076b117c06052cb",
            "placeholder": "​",
            "style": "IPY_MODEL_86f943fd4b694711ab174ec334c653a6",
            "value": " 285/285 [00:00&lt;00:00, 14.0kB/s]"
          }
        },
        "44e01017275c4e23b036424c61c336fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "962270b3f0aa47b88265a4982aa1d0e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1a52213370143a2867c7f55369f6f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d8adce041264808ab961843960dc9f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "239a76d1404346a4b0a4b2e12dbc92f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad97b62eda2747688076b117c06052cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86f943fd4b694711ab174ec334c653a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2058a13d2674acd91c5c3499fb3406a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2b64de67665462b898ea7903ce2e398",
              "IPY_MODEL_b1c3d0f2aa984644acd61e0338189725",
              "IPY_MODEL_eb8102905e184222a955d73fad4b562c"
            ],
            "layout": "IPY_MODEL_1c8a5b8eea764379a7fe3327f3d5fcde"
          }
        },
        "b2b64de67665462b898ea7903ce2e398": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c403bab3dfb640dfa9cf8c0b74ead778",
            "placeholder": "​",
            "style": "IPY_MODEL_356e563fc328456db2bb446133700452",
            "value": "vocab.txt: 100%"
          }
        },
        "b1c3d0f2aa984644acd61e0338189725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccaff2c16e4440828d4adc46e2c3e6cb",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39612e8fdaa3412683a9806930bfe6e5",
            "value": 231508
          }
        },
        "eb8102905e184222a955d73fad4b562c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d83201051be40148c32d78ff0171b7f",
            "placeholder": "​",
            "style": "IPY_MODEL_f2c7c51bc988445c9a04c762a3406e47",
            "value": " 232k/232k [00:00&lt;00:00, 6.87MB/s]"
          }
        },
        "1c8a5b8eea764379a7fe3327f3d5fcde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c403bab3dfb640dfa9cf8c0b74ead778": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "356e563fc328456db2bb446133700452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccaff2c16e4440828d4adc46e2c3e6cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39612e8fdaa3412683a9806930bfe6e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d83201051be40148c32d78ff0171b7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2c7c51bc988445c9a04c762a3406e47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8b44c3690d94072af82ab15abbd415a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7cf7274cdf554c8dbe48452081123b7d",
              "IPY_MODEL_1f4d827dd8ec4603bfb1c12f8aedb2c9",
              "IPY_MODEL_9339203b69184dc5a8baa24ba523e832"
            ],
            "layout": "IPY_MODEL_541311f41a544d7ea722061bbf54e89b"
          }
        },
        "7cf7274cdf554c8dbe48452081123b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e32f7c43f3c4cffa82bdc3ea0446d19",
            "placeholder": "​",
            "style": "IPY_MODEL_636cbfe7b4ff4ffbba35c066165cbc28",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "1f4d827dd8ec4603bfb1c12f8aedb2c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c005642ec2ff46df8a0946adf97f027b",
            "max": 17756393,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a188b603aa2248d898c68f9a75cab30e",
            "value": 17756393
          }
        },
        "9339203b69184dc5a8baa24ba523e832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad31ccffe7de49d1a4b97377c8bf74c3",
            "placeholder": "​",
            "style": "IPY_MODEL_75baef9ef3de4827b7b0d21a13a76ed5",
            "value": " 17.8M/17.8M [00:00&lt;00:00, 39.7MB/s]"
          }
        },
        "541311f41a544d7ea722061bbf54e89b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e32f7c43f3c4cffa82bdc3ea0446d19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "636cbfe7b4ff4ffbba35c066165cbc28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c005642ec2ff46df8a0946adf97f027b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a188b603aa2248d898c68f9a75cab30e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad31ccffe7de49d1a4b97377c8bf74c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75baef9ef3de4827b7b0d21a13a76ed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}